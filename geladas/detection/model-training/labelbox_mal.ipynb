{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used for model assisted labeling with Labelbox\n",
    "(Code is modified from Labelbox tutorials on their website)\n",
    " Additionally it allows uploading overlay images in Labelbox. Based on my current understanding of Labelbox this makes things a little convoluted since the overlays need to be uploaded to the cloud first. Currently I do this by first including them in a seperate dataset. This can be ignored if the images are already hosted elsewhere online. There is probably a smoother way to do this already or hopefully labelbox makes that possible soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import uuid\n",
    "import json\n",
    "import datetime as dt\n",
    "from io import BytesIO\n",
    "from typing import Dict, Any, Tuple\n",
    "from getpass import getpass\n",
    "\n",
    "import ndjson\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "\n",
    "from labelbox.schema.ontology import OntologyBuilder, Tool, Classification, Option\n",
    "from labelbox import Client, LabelingFrontend\n",
    "import labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geladas_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "local_paths_file = os.path.join(geladas_root, 'local-paths.json')\n",
    "with open(local_paths_file, \"r\") as json_file:\n",
    "    local_paths = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LB_API_KEY = os.environ.get(\"LABELBOX_API_KEY\") # uncomment if key stored locally\n",
    "# This key comes from one's labelbox account\n",
    "LB_API_KEY = local_paths[\"labelbox_key\"]\n",
    "# Create Labelbox client\n",
    "lb = labelbox.Client(api_key=LB_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"DJI_0205_boost\" # \"train\", \"validation\", \"test\"\n",
    "\n",
    "\n",
    "# Folder that contains images for annoation\n",
    "# To work with overlays, assumes that images that will actually be annotated \n",
    "# end with _f in their files names while the overlay image before and after\n",
    "# end with _a and _b respectively. Otherwise annotated and overlay image triplets\n",
    "# have identical file names\n",
    "\n",
    "# Can get images in this format from \"extract_annotation_images.ipynb\"\n",
    "annotation_images_folder = os.path.join(local_paths[\"annotations_folder\"],\n",
    "                                        \"extracted_frames\", \"crops\", \n",
    "                                        dataset_type)\n",
    "\n",
    "annotation_image_files = glob.glob(os.path.join(annotation_images_folder, \"*.jpg\"))\n",
    "\n",
    "dataset_name = f\"geladas-1.0-{dataset_type}-set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# # Create Labelbox client\n",
    "# delete mdo = lb.get_data_row_metadata_ontology()\n",
    "\n",
    "# Create a new dataset\n",
    "# This dataset is just for uploading all images to the cloud\n",
    "# In a second dataset some of these images will become overlay images\n",
    "# So the user can use animal movement to help detect crypric individuals\n",
    "flat_dataset = lb.create_dataset(name=f\"{dataset_name}-flat\")\n",
    "\n",
    "# Create data payload\n",
    "# External ID is recommended to identify your data\n",
    "my_data_rows = []\n",
    "for image_file in annotation_image_files:\n",
    "    my_data_rows.append({\"row_data\": image_file,\n",
    "                         \"external_id\": os.path.basename(image_file)\n",
    "                        }\n",
    "                       )\n",
    "# Bulk add data rows to the dataset\n",
    "task = flat_dataset.create_data_rows(my_data_rows)\n",
    "\n",
    "task.wait_till_done()\n",
    "print(task.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just the files are going to actually be annotated (marked by _f)\n",
    "focal_images = sorted(glob.glob(os.path.join(annotation_images_folder, \"*_f.jpg\")))\n",
    "focal_names = [os.path.basename(f) for f in focal_images]\n",
    "# dataset_name = \"overlay-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "dataset = lb.create_dataset(name=dataset_name)\n",
    "\n",
    "my_data_rows = []\n",
    "\n",
    "for focal_name in focal_names:\n",
    "    prev_name = focal_name.split(\"_f.jpg\")[0] + \"_a.jpg\"\n",
    "    next_name = focal_name.split(\"_f.jpg\")[0] + \"_b.jpg\"\n",
    "    data_row = flat_dataset.data_row_for_external_id(focal_name)\n",
    "    prev_row = flat_dataset.data_row_for_external_id(prev_name)\n",
    "    next_row = flat_dataset.data_row_for_external_id(next_name)\n",
    "\n",
    "    my_data_rows.append({\"row_data\": data_row.row_data,\n",
    "                         \"external_id\": data_row.external_id,\n",
    "                         \"attachments\": [\n",
    "                             {\n",
    "                                 \"type\": \"IMAGE_OVERLAY\",\n",
    "                                 \"value\": prev_row.row_data\n",
    "                             },\n",
    "                             {\n",
    "                                 \"type\": \"IMAGE_OVERLAY\",\n",
    "                                 \"value\": next_row.row_data\n",
    "                             }\n",
    "                         ]\n",
    "                        }\n",
    "                       )\n",
    "\n",
    "# Bulk add data rows to the dataset\n",
    "task = dataset.create_data_rows(my_data_rows)\n",
    "\n",
    "task.wait_till_done()\n",
    "print(task.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point the nessisary datasets have been added to labelbox.\n",
    "Go to labelbox to create the project for annotating this images\n",
    "- When creating the project, choose the dataset with the name defined above (ignore the 'flat' one)\n",
    "- After the project is created, find the project ID in the export tab of the project (use below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on\n",
    "# https://colab.research.google.com/drive/1DfZwbUAs1EeQXwbZeTPan-T24-VQ9ZCp?usp=sharing#scrollTo=LI5Q2j0WQAh6\n",
    "## get project ontology from labelbox\n",
    "def get_ontology(project_id, client):\n",
    "    response = client.execute(\n",
    "                \"\"\"\n",
    "                query getOntology (\n",
    "                    $project_id : ID!){ \n",
    "                    project (where: { id: $project_id }) { \n",
    "                        ontology { \n",
    "                            normalized \n",
    "                        } \n",
    "                    }\n",
    "                }\n",
    "                \"\"\",\n",
    "                {\"project_id\": project_id})\n",
    "            \n",
    "    ontology = response['project']['ontology']['normalized']['tools']\n",
    "\n",
    "    ##Return list of tools and embed category id to be used to map classname during training and inference\n",
    "    mapped_ontology = []\n",
    "    thing_classes = []\n",
    "    \n",
    "    i=0\n",
    "    for item in ontology:\n",
    "#         if item['tool']=='superpixel' or item['tool']=='rectangle':\n",
    "        item.update({'category': i})\n",
    "        mapped_ontology.append(item)\n",
    "        thing_classes.append(item['name'])\n",
    "        i=i+1         \n",
    "\n",
    "    return mapped_ontology, thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the specific project on labelbox that should be preannotated\n",
    "PROJECT_ID = 'cl128qx6d6vrg0z5qhdercux7'\n",
    "project = lb.get_project(PROJECT_ID)\n",
    "ontology, thing_classes = get_ontology(PROJECT_ID, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gelada', 'Human']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In out case the thing classes are in a different order so need to be modifed\n",
    "# thing_classes = [\"Human\", \"Gelada\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inport the model we already trained in \"train_gelada_detector.ipynb\"\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "# Name of the model to use for model assisted labeling\n",
    "model_name = \"LRscheduler-cropped-color-aug_maxiter-6400_lr-0.0019_detectPerIm-200_minsize-0_batchsize-8\"\n",
    "model_folder = os.path.join(os.path.dirname(os.getcwd()), \n",
    "                             'model-training', 'output', model_name)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(os.path.join(local_paths[\"detectron_path\"], \n",
    "                                 \"configs\", \"COCO-Detection\",\n",
    "                                 \"faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "                                )\n",
    "                   )\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (256)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
    "cfg.OUTPUT_DIR = model_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gelada', 'Human']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted boxes 24\n",
      "predicted boxes 0\n",
      "predicted boxes 24\n",
      "predicted boxes 1\n",
      "predicted boxes 2\n",
      "predicted boxes 7\n",
      "predicted boxes 0\n",
      "predicted boxes 8\n",
      "predicted boxes 0\n",
      "predicted boxes 3\n",
      "predicted boxes 9\n",
      "predicted boxes 1\n",
      "predicted boxes 2\n",
      "predicted boxes 0\n",
      "predicted boxes 0\n",
      "predicted boxes 21\n",
      "predicted boxes 14\n",
      "predicted boxes 0\n",
      "predicted boxes 9\n",
      "predicted boxes 0\n",
      "<BulkImportRequest {'created_at': datetime.datetime(2022, 3, 22, 15, 34, 31, 354000, tzinfo=datetime.timezone.utc), 'error_file_url': None, 'input_file_url': 'https://storage.googleapis.com/labelbox-predictions-import-prod/uploaded_predictions/ck87gvhf2j2sw0811cdnogdxm/7bd04fc0-1d5a-c196-ad7f-2187bfcff79f-cl128qx6d6vrg0z5qhdercux7__pre-labeling-geladas-1.0-DJI_0205_boost-set.ndjson?GoogleAccessId=api-prod%40labelbox-193903.iam.gserviceaccount.com&Expires=1648568071&Signature=B0qqLkrsJgDzx3iSkUETBFOkSSVzLJ8XqHb8mbGZLNeO8GHAFpQtvPlAqNiXmqu6z0Ok9xFPgpc3A66jg5q96dNFe1i%2FYxaI4QkDD1UGi%2Ff1NYluwh8i4mhmKz%2BUHSYyKwNBuPwd87Mr1%2BnEFkplkOvvH%2B3zMrsrM4wD6wNSgqrhs%2BZRllFG%2BfrcB7Eg%2F2CqqRtwVBTBfZj%2BVLbs6RpRmf6pMrk%2FfhYYs9nWcDiROmUXu4Gdh5w291Dk66yZ4U1g0mvdS2T7zxOU0%2Fa3JLGA%2FpVReRP7Mj3ffpUBsQnHhykiitSBQRVdO%2BcMeyVNjNmbek9PUufDEs5ShSuD3JMseA%3D%3D', 'name': 'pre-labeling-geladas-1.0-DJI_0205_boost-set', 'state': <BulkImportRequestState.RUNNING: 'RUNNING'>, 'status_file_url': None, 'uid': '9ddf8141-b1d9-05c8-cf0f-9abbd79a9df0'}>\n",
      "State BulkImportRequestState.FINISHED\n"
     ]
    }
   ],
   "source": [
    "# Check training\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best-model-config-iter-1319-loss-0.5798989905295178.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.DATASETS.TEST = (\"val\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "base_folder = local_paths[\"annotations_folder\"]\n",
    "train_json = os.path.join(base_folder, 'train.json') \n",
    "\n",
    "predictions = []\n",
    "\n",
    "for data_row in dataset.data_rows():\n",
    "    file = os.path.join(annotation_images_folder, data_row.external_id)\n",
    "    im = cv2.imread(file)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    categories = outputs[\"instances\"].to(\"cpu\").pred_classes.numpy()\n",
    "    predicted_boxes = outputs[\"instances\"].to(\"cpu\").pred_boxes\n",
    "    print(f\"predicted boxes {len(predicted_boxes)}\")\n",
    "    if len(categories) != 0:\n",
    "        for i in range(len(categories)):\n",
    "            \n",
    "            classname = thing_classes[categories[i]]\n",
    "            \n",
    "            for item in ontology:\n",
    "                if classname==item['name']:\n",
    "                    schema_id = item['featureSchemaId']\n",
    "   \n",
    "            bbox = predicted_boxes[i].tensor.numpy()[0]\n",
    "            bbox_dimensions = {'left': int(bbox[0]), 'top': int(bbox[1]), \n",
    "                               'width': int(bbox[2]-bbox[0]), \n",
    "                               'height': int(bbox[3]-bbox[1])}\n",
    "            predictions.append({\"uuid\": str(uuid.uuid4()),\n",
    "                                'schemaId': schema_id, \n",
    "                                'bbox': bbox_dimensions, \n",
    "                                'dataRow': { 'id': data_row.uid }})\n",
    "            \n",
    "    \n",
    "    \n",
    "job_name = f\"pre-labeling-{dataset_name}\"\n",
    "\n",
    "upload_job = project.upload_annotations( \n",
    "    name=job_name, \n",
    "    annotations=predictions)\n",
    "\n",
    "print(upload_job)\n",
    "\n",
    "upload_job.wait_until_done()\n",
    "\n",
    "print(\"State\", upload_job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
