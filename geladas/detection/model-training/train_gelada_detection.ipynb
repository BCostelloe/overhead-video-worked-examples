{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "geladas_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "local_paths_file = os.path.join(geladas_root, 'local-paths.json')\n",
    "with open(local_paths_file, \"r\") as json_file:\n",
    "    local_paths = json.load(json_file)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\n",
    "    os.path.join(local_paths[\"general_dection_path\"],\n",
    "                 \"detectron2_classes\"\n",
    "                )\n",
    ")\n",
    "from DetectionDatasetMapper import DetectionDatasetMapper\n",
    "from DetectionTrainer import DetectionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Was designed with 0.2.1\n",
    "detectron2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = local_paths[\"base_gelada\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = os.path.join(base_folder, \"annotation\", \"annotated_images\")\n",
    "train_json = os.path.join(base_folder, \"annotation\", \"train.json\") \n",
    "val_json = os.path.join(base_folder, \"annotation\", \"val.json\")\n",
    "\n",
    "register_coco_instances(\"train\", {}, train_json, images_folder)\n",
    "register_coco_instances(\"val\", {}, val_json, images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(\"train\")\n",
    "train_dicts = DatasetCatalog.get(\"train\")\n",
    "val_dicts = DatasetCatalog.get(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 training images \n",
      "13 validation images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gelada', 'human']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_images = len(train_dicts)\n",
    "num_val_images = len(val_dicts)\n",
    "print(f\"{num_train_images} training images \\n\"\n",
    "      + f\"{num_val_images} validation images\")\n",
    "\n",
    "train_metadata = MetadataCatalog.get(\"train\")\n",
    "print(f\"Annotated classes: {train_metadata.get('thing_classes')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/LRscheduler-cropped-color-aug-test-new-dataloader_maxiter-80_lr-0.0019_detectPerIm-200_minsize-0_batchsize-8/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# To identify model\n",
    "name = \"LRscheduler-cropped-color-aug-test-new-dataloader\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\n",
    "    os.path.join(local_paths[\"detectron_path\"],\n",
    "                 \"configs\", \"COCO-Detection\",\n",
    "                 \"faster_rcnn_R_50_FPN_3x.yaml\")\n",
    ")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATASETS.TEST = (\"val\",)\n",
    "# CHANGE BASED ON THE NUMBER OF CORES ON COMPUTER\n",
    "cfg.DATALOADER.NUM_WORKERS = 6\n",
    "cfg.DATALOADER.ASPECT_RATIO_GROUPING = False\n",
    "# Use pre-trained weights for transfer learning\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "    \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"\n",
    ")\n",
    "# Change batch size based on amount of memory in GPU\n",
    "# (Make the number smaller if getting GPU memory errors)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.0019\n",
    "# Maximum number of times to cycle through training data while training\n",
    "max_epochs = 10\n",
    "iter_per_epoch = num_train_images // cfg.SOLVER.IMS_PER_BATCH\n",
    "cfg.SOLVER.MAX_ITER = max_epochs * iter_per_epoch\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupValLossLR\"\n",
    "# How often to save a checkpoint while training\n",
    "# 0 to save best model based on minimum val loss\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 0 \n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 5 \n",
    "# This number should be bigger than the number\n",
    "# of expected objects in each frame\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (256)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(train_metadata.get(\"thing_classes\"))\n",
    "# How often to check model performance on the validation set\n",
    "# if iter_per_epoch then every epoch\n",
    "cfg.TEST.EVAL_PERIOD = iter_per_epoch \n",
    "# Should be larger than max number of expected objects in image\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (0)\n",
    "cfg.INPUT.MIN_SIZE_TEST = (0)\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = (4100)\n",
    "cfg.INPUT.MAX_SIZE_TEST = (4100)\n",
    "\n",
    "# Set the data augementation regime\n",
    "cfg.INPUT.CROP.ENABLED = True\n",
    "cfg.INPUT.CROP.TYPE = \"absolute\"\n",
    "cfg.INPUT.CROP.SIZE = (720.0, 720.0) # was 720, 1280\n",
    "cfg.INPUT.RESIZE = False\n",
    "cfg.INPUT.RESIZE_SHAPE = (720, 2048)\n",
    "cfg.INPUT.VER_FLIP = True\n",
    "cfg.INPUT.HOR_FLIP = True\n",
    "cfg.INPUT.AUG_ON_TEST = False\n",
    "cfg.INPUT.CONTRAST = True\n",
    "cfg.INPUT.CONTRAST_RANGE = (.5, 1.5)\n",
    "cfg.INPUT.BRIGHTNESS = True\n",
    "cfg.INPUT.BRIGHTNESS_RANGE = (.3, 1.7)\n",
    "cfg.INPUT.SATURATION = True\n",
    "cfg.INPUT.SATURATION_RANGE = (.7, 1.4)\n",
    "\n",
    "\n",
    "output_name = '{}_maxiter-{}_lr-{}_detectPerIm-{}_minsize-{}_batchsize-{}'.format(\n",
    "    name, cfg.SOLVER.MAX_ITER, cfg.SOLVER.BASE_LR, cfg.TEST.DETECTIONS_PER_IMAGE, \n",
    "    np.min(cfg.INPUT.MIN_SIZE_TRAIN), cfg.SOLVER.IMS_PER_BATCH\n",
    ")\n",
    "cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, output_name)\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save the config file for future reference\n",
    "yaml_file = os.path.join(cfg.OUTPUT_DIR, \"config.yaml\")\n",
    "with open(yaml_file, 'w') as file:\n",
    "    file.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/LRscheduler-cropped-color-aug-test-new-dataloader_maxiter-80_lr-0.0019_detectPerIm-200_minsize-0_batchsize-8'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the training images with augmentation and annotations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "show_images = True\n",
    "show_test_images = False\n",
    "if show_images:\n",
    "    \n",
    "    mapper = DetectionDatasetMapper(cfg)\n",
    "    if show_test_images:\n",
    "        loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])\n",
    "    else:\n",
    "        loader = build_detection_train_loader(cfg, mapper=mapper)\n",
    "    loader_iter = iter(loader)\n",
    "    for _ in range(1):\n",
    "        batch = next(loader_iter)\n",
    "        for im_dict in batch:\n",
    "            image = im_dict['image'].numpy()\n",
    "            image = np.transpose(image, [1, 2, 0])\n",
    "            plt.figure(figsize=(20,20))\n",
    "            visualizer = Visualizer(image[:, :, ::-1], \n",
    "                                    metadata=train_metadata, \n",
    "                                    scale=1.0)\n",
    "\n",
    "            vis = visualizer.overlay_instances(\n",
    "                boxes=im_dict['instances'].get('gt_boxes'), \n",
    "                labels=im_dict['instances'].get('gt_classes'),\n",
    "                alpha=1.0)\n",
    "\n",
    "            plt.imshow(vis.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/10 11:28:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/10 11:28:55 detectron2]: \u001b[0mCropGen used in training: RandomCrop(crop_type='absolute', crop_size=(720.0, 720.0))\n",
      "Train loader with custom mapper.\n",
      "\u001b[32m[01/10 11:28:55 d2.data.datasets.coco]: \u001b[0mLoaded 69 images in COCO format from /mount/zfs-kn/gelada_project/annotation/train.json\n",
      "\u001b[32m[01/10 11:28:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 69 images left.\n",
      "\u001b[32m[01/10 11:28:55 d2.data.common]: \u001b[0mSerializing 69 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 11:28:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.15 MiB\n",
      "\u001b[32m[01/10 11:28:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/10 11:28:55 d2.data.datasets.coco]: \u001b[0mLoaded 13 images in COCO format from /mount/zfs-kn/gelada_project/annotation/val.json\n",
      "\u001b[32m[01/10 11:28:55 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   gelada   | 119          |   human    | 2            |\n",
      "|            |              |            |              |\n",
      "|   total    | 121          |            |              |\u001b[0m\n",
      "\u001b[32m[01/10 11:28:55 d2.data.common]: \u001b[0mSerializing 13 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/10 11:28:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "hooks: [<detectron2.engine.hooks.IterationTimer object at 0x7f472016ad68>, <LRScheduler.LRScheduler object at 0x7f472016ae10>, None, <detectron2.engine.hooks.EvalHook object at 0x7f472016ae48>, <LossEvalHook.LossEvalHook object at 0x7f47026cd198>, <detectron2.engine.hooks.PeriodicWriter object at 0x7f4702780be0>]\n"
     ]
    }
   ],
   "source": [
    "trainer = DetectionTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training quality\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best-model-config-iter-896-loss-0.8034359399295811.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.DATASETS.TEST = (\"val\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "for d in random.sample(val_dicts, 3):\n",
    "# for d in train_dicts:\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=train_metadata,\n",
    "                   scale=0.8,\n",
    "                   \n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(v.get_image()[:, :, ::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/LRscheduler-cropped-color-aug_maxiter-6400_lr-0.0019_detectPerIm-200_minsize-0_batchsize-8'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
